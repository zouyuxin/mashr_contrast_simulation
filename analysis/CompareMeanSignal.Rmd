---
title: "Comparing with mean (with signal)"
author: "Yuxin Zou"
date: 2018-01-10
output: html_document
---
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the R version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r R-version, echo=FALSE, results='asis'}
```

```{r, echo=FALSE}
# TEMPORARY.
knitr::opts_chunk$set(eval = TRUE)
```

```{r, echo=FALSE}
library(ashr)
library(plyr)
library(mvtnorm)
library(assertthat)
source('~/Documents/GitHub/mashr-zou/R/compute_covs.R')
source('~/Documents/GitHub/mashr-zou/R/cov_udi.R')
source('~/Documents/GitHub/mashr-zou/R/data2cov.R')
source('~/Documents/GitHub/mashr-zou/R/ed.R')
source('~/Documents/GitHub/mashr-zou/R/est_cor.R')
source('~/Documents/GitHub/mashr-zou/R/get_functions.R')
source('~/Documents/GitHub/mashr-zou/R/likelihoods_origdata.R')
source('~/Documents/GitHub/mashr-zou/R/likelihoods_scaleddata.R')
source('~/Documents/GitHub/mashr-zou/R/mash.R')
source('~/Documents/GitHub/mashr-zou/R/opt.R')
source('~/Documents/GitHub/mashr-zou/R/plots.R')
source('~/Documents/GitHub/mashr-zou/R/posterior.R')
source('~/Documents/GitHub/mashr-zou/R/posterior_common_cov.R')
source('~/Documents/GitHub/mashr-zou/R/posterior_lowmem.R')
source('~/Documents/GitHub/mashr-zou/R/RcppExports.R')
source('~/Documents/GitHub/mashr-zou/R/set_data.R')
source('~/Documents/GitHub/mashr-zou/R/simulations.R')
```

The data simulated here only has signals in the first two conditions. $\delta$ represents the deviation from the mean.

$$\hat{\delta}_{j}|\delta_{j} \sim N(\delta_{j}, \frac{1}{2}LL')$$
$$\delta_{j}|\pi \sim N(0,\left(\begin{array}{c c}
A & 0 \\
0 & 0
\end{array}\right)) \quad A = \left(\begin{array}{c c} 1 & -1 \\ -1 & 1 \end{array} \right)$$

The data was generated using $R=10$.

```{r, echo=FALSE}
set.seed(1)
R = 10
data = sim.mean(nsamp=10000, ncond=R)
```

```{r, echo=FALSE}
L = matrix(-1/R, R, R)
L[cbind(1:R,1:R)] = (R-1)/R
L = L[1:(R-1),]
row.names(L) = seq(1,R-1)
mash_data = mash_set_data(Bhat=data$Chat, Shat=data$Shat)
mash_data_L = mash_set_data_contrast(mash_data, L)
```
```{r, echo=FALSE}
U.c = cov_canonical(mash_data_L)
mashcontrast.model = mash(mash_data_L, U.c, algorithm.version = 'R')
```
There are `r length(get_significant_results(mashcontrast.model))` discoveries. The covariance structure found here is:
```{r}
barplot(get_estimated_pi(mashcontrast.model),las = 2)
```

# Subtract mean directly

If we subtract the mean from the data directly, ignoring the correlation structure.
$$Var(\hat{c}_{j,r}-\bar{\hat{c}_{j}}) = \frac{1}{2} + \frac{1}{2R}$$
```{r, echo=FALSE}
Indep.data = mash_set_data(Bhat = (data$Chat - apply(data$Chat,1, mean))[,1:(R-1)],
                           Shat = matrix(sqrt(0.5+1/(R*2)), nrow(data$Chat), R-1))
U.c = cov_canonical(mash_data_L)
Indep.model = mash(Indep.data, U.c, algorithm.version = 'R')
```
There are `r length(get_significant_results(Indep.model))` discoveries, which is less than the `mashcommonbaseline` model. The covariance structure found here is:
```{r}
barplot(get_estimated_pi(Indep.model),las = 2)
```

# Note:

The data was generated with signals in the first two conditions ($c_{j,1}, c_{j,2}$). The contrast matrix L using here discards the for the last conditions. The deviations are $\hat{c}_{j,1} - \bar{\hat{c}_{j}}, \hat{c}_{j,2} - \bar{\hat{c}_{j}}, \cdots, \hat{c}_{j,R-1} - \bar{\hat{c}_{j}}$.

However, the contrast matrix L can discard any deviation from $\hat{c}_{j,1} - \bar{\hat{c}_{j}}, \cdots, \hat{c}_{j,R} - \bar{\hat{c}_{j}}$.

Let's try to model the deviations $\hat{c}_{j,2} - \bar{\hat{c}_{j}}, \cdots, \hat{c}_{j,R} - \bar{\hat{c}_{j}}$.

## Mash model
```{r, echo=FALSE}
L = matrix(-1/R, R, R)
L[cbind(1:R,1:R)] = (R-1)/R
L = L[2:R,]
row.names(L) = seq(2,R)
mash_data = mash_set_data(Bhat=data$Chat, Shat=data$Shat)
mash_data_L = mash_set_data_contrast(mash_data, L)
```
```{r, echo=FALSE}
U.c = cov_canonical(mash_data_L)
mashcontrast.model = mash(mash_data_L, U.c, algorithm.version = 'R')
```
There are `r length(get_significant_results(mashcontrast.model))` discoveries, which increases a lot compared with the previous `mash` model. The covariance structure found here is:
```{r}
barplot(get_estimated_pi(mashcontrast.model),las = 2)
```

# Subtract mean directly

If we subtract the mean from the data directly, ignoring the correlation structure.
$$Var(\hat{c}_{j,r}-\bar{\hat{c}_{j}}) = \frac{1}{2} + \frac{1}{2R}$$
```{r, echo=FALSE}
Indep.data = mash_set_data(Bhat = (data$Chat - apply(data$Chat,1, mean))[,2:R],
                           Shat = matrix(sqrt(0.5+1/(R*2)), nrow(data$Chat), R-1))
U.c = cov_canonical(mash_data_L)
Indep.model = mash(Indep.data, U.c, algorithm.version = 'R')
```
There are `r length(get_significant_results(Indep.model))` discoveries, which is less than the `mash` model. The covariance structure found here is:
```{r}
barplot(get_estimated_pi(Indep.model),las = 2)
```

In summary, when comparing the observations with the mean, the `mashcommonbaseline` method has more discoveries then subtracting the mean directly from the data. But the differences is not obvious.

Moreover, after we subtract the mean from the data, we need to discard a random column of the data to avoid singularity. The choice of the column will influence the result.

# Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
